{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d520818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sentence Transformer with LinearSVC for 2 classes\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix as sk_confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import numpy as np\n",
    "import torch\n",
    "import scipy\n",
    "\n",
    "# Initialize the tokenizer and model for 'stsb-bert-base'\n",
    "tokenizer = BertTokenizer.from_pretrained('sentence-transformers/stsb-bert-base')\n",
    "bert_model = BertModel.from_pretrained('sentence-transformers/stsb-bert-base')\n",
    "\n",
    "def encode_texts(texts):\n",
    "    encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "    with torch.no_grad():\n",
    "        model_output = bert_model(**encoded_input)\n",
    "    return model_output.pooler_output.detach().numpy()\n",
    "\n",
    "def extract_features(narratives):\n",
    "    features = []\n",
    "    domain_terms = [\"credit\", \"debt\", \"loan\", \"score\", \"report\", \"financial\", \"consumer\", \n",
    "                    \"account\", \"law\", \"act\", \"reporting\", \"services\", \"refund\", \"card\"]\n",
    "    for narrative in narratives:\n",
    "        sentences = nltk.sent_tokenize(narrative)\n",
    "        avg_sentence_length = sum(len(nltk.word_tokenize(sentence)) for sentence in sentences) / len(sentences) if sentences else 0\n",
    "        domain_term_count = sum(narrative.lower().count(term) for term in domain_terms)\n",
    "        features.append([avg_sentence_length, domain_term_count])\n",
    "    return features\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "file_path = 'complaints-official-4-classes.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "df = df[['Consumer complaint narrative', 'Label']]\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Extract manual features\n",
    "manual_features = extract_features(df['Consumer complaint narrative'])\n",
    "\n",
    "# Initialize TF-IDF Vectorizer and compute TF-IDF features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=500)\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(df['Consumer complaint narrative'])\n",
    "\n",
    "# Encode the data using BERT\n",
    "df['encoded_texts'] = df['Consumer complaint narrative'].apply(lambda x: encode_texts([x])[0])\n",
    "\n",
    "# Combine BERT encodings, TF-IDF features, and manual features\n",
    "df['manual_features'] = np.array(manual_features)\n",
    "df['tfidf_features'] = list(tfidf_features)\n",
    "\n",
    "combined_features = np.hstack([np.vstack(df['encoded_texts']),df['manual_features'],tfidf_features.toarray()])\n",
    "\n",
    "# Split the dataset into 20% training, 60% test, and 20% validation sets\n",
    "train_features, remaining_features, train_labels, remaining_labels = train_test_split(combined_features, df['Label'], test_size=0.80, stratify=df['Label'])\n",
    "test_features, val_features, test_labels, val_labels = train_test_split(remaining_features, remaining_labels, test_size=0.25, stratify=remaining_labels) # 0.25 * 0.80 = 0.20\n",
    "\n",
    "# Initialize and train the LinearSVC model\n",
    "model = LinearSVC(random_state=0)\n",
    "model.fit(train_features, train_labels)\n",
    "\n",
    "# Make predictions on test and validation sets\n",
    "test_predictions = model.predict(test_features)\n",
    "val_predictions = model.predict(val_features)\n",
    "\n",
    "# Calculate metrics for test set\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "\n",
    "# Calculate metrics for validation set\n",
    "val_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "val_f1 = f1_score(val_labels, val_predictions, average='weighted')\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print(f'Test F1 Score: {test_f1}')\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print(f'Validation F1 Score: {val_f1}')\n",
    "\n",
    "# Confusion Matrix for test set\n",
    "test_conf_matrix = sk_confusion_matrix(test_labels, test_predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(test_conf_matrix, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Test Set Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Print incorrect predictions on test set\n",
    "incorrect_test_predictions = [(text, pred, actual) for text, pred, actual in zip(df.loc[test_labels.index, 'Consumer complaint narrative'], test_predictions, test_labels) if pred != actual]\n",
    "\n",
    "print(\"Incorrect Predictions on Test Set:\")\n",
    "for text, pred, label in incorrect_test_predictions:\n",
    "    print(f\"Text: {text}, Predicted: {pred}, Actual: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d9784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sentence Transformer with LinearSVC for 4 classes\n",
    "import torch\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix as sk_confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import numpy as np\n",
    "\n",
    "def extract_features(narratives):\n",
    "    features = []\n",
    "    domain_terms = [\n",
    "        \"money\", \"help\", \"credit\", \"account\", \"paid\", \"debt\", \"card\",\n",
    "        \"loan\", \"financial\", \"consumer\", \"payment\", \"service\",\n",
    "        \"reporting\", \"act\", \"law\", \"unauthorized\", \"section\", \"usc\", \"rights\"\n",
    "    ]\n",
    "    for narrative in narratives:\n",
    "        sentences = nltk.sent_tokenize(narrative)\n",
    "        avg_sentence_length = sum(len(nltk.word_tokenize(sentence)) for sentence in sentences) / len(sentences) if sentences else 0\n",
    "        domain_term_count = sum(narrative.lower().count(term) for term in domain_terms)\n",
    "        features.append([avg_sentence_length, domain_term_count])\n",
    "    return features\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "file_path = 'complaints-official-4-classes.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "df = df[['Consumer complaint narrative', 'Label']]\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Extract manual features\n",
    "manual_features = extract_features(df['Consumer complaint narrative'])\n",
    "\n",
    "# Initialize TF-IDF Vectorizer and compute TF-IDF features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=500)\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(df['Consumer complaint narrative'])\n",
    "\n",
    "# Initialize the tokenizer and model for 'stsb-bert-base'\n",
    "tokenizer = BertTokenizer.from_pretrained('sentence-transformers/stsb-bert-base')\n",
    "bert_model = BertModel.from_pretrained('sentence-transformers/stsb-bert-base')\n",
    "\n",
    "def encode_texts(texts):\n",
    "    encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "    with torch.no_grad():\n",
    "        model_output = bert_model(**encoded_input)\n",
    "    return model_output.pooler_output.detach().numpy()\n",
    "\n",
    "# Encode the data and extract features\n",
    "df['encoded_texts'] = df['Consumer complaint narrative'].apply(lambda x: encode_texts([x])[0])\n",
    "df['manual_features'] = manual_features\n",
    "df['tfidf_features'] = list(tfidf_features)\n",
    "\n",
    "# Combine BERT encodings, TF-IDF features, and manual features\n",
    "df['combined_features'] = df.apply(lambda row: np.concatenate((row['encoded_texts'], row['manual_features'], row['tfidf_features'].toarray()[0])), axis=1)\n",
    "\n",
    "# Split the dataset into 20% training, 60% test, and 20% validation sets\n",
    "train_data, remaining_data = train_test_split(df, test_size=0.80, stratify=df['Label'])\n",
    "test_data, val_data = train_test_split(remaining_data, test_size=0.25, stratify=remaining_data['Label'])  # 0.25 * 0.80 = 0.20\n",
    "\n",
    "# Prepare the data for training, testing, and validation sets\n",
    "X_train = np.vstack(train_data['combined_features'])\n",
    "y_train = train_data['Label'].values\n",
    "X_test = np.vstack(test_data['combined_features'])\n",
    "y_test = test_data['Label'].values\n",
    "X_val = np.vstack(val_data['combined_features'])\n",
    "y_val = val_data['Label'].values\n",
    "\n",
    "# Initialize and train the LinearSVC model\n",
    "model = LinearSVC()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],  # Expanded range\n",
    "    'tol': [1e-5, 1e-4, 1e-3, 1e-2],\n",
    "    'max_iter': [500, 1000, 2000, 5000]\n",
    "}\n",
    "\n",
    "# Make predictions on the test and validation sets\n",
    "test_predictions = model.predict(X_test)\n",
    "val_predictions = model.predict(X_val)\n",
    "\n",
    "# Test and validation metrics\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_f1 = f1_score(y_test, test_predictions, average='weighted')\n",
    "val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "val_f1 = f1_score(y_val, val_predictions, average='weighted')\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "print(f'Test F1 Score: {test_f1}')\n",
    "print(f'Validation Accuracy: {val_accuracy}')\n",
    "print(f'Validation F1 Score: {val_f1}')\n",
    "\n",
    "# Confusion Matrix for validation set\n",
    "val_conf_matrix = sk_confusion_matrix(y_val, val_predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(val_conf_matrix, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Validation Set Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Print incorrect predictions on validation set\n",
    "incorrect_val_predictions = [(text, pred, actual) for text, pred, actual in zip(val_data['Consumer complaint narrative'], val_predictions, y_val) if pred != actual]\n",
    "\n",
    "print(\"Incorrect Predictions on Validation Set:\")\n",
    "for text, pred, label in incorrect_val_predictions:\n",
    "    print(f\"Text: {text}, Predicted: {pred}, Actual: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cef340",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
